version: "2.1" # To keep the docker-resource constraints under deploy active. Else we need swarm in v3

services:
  llm-service:
    build: ./core
    restart: unless-stopped
    environment:
      FLASK_ENV: ${FLASK_ENV} # Autorestarts flask when code changes are detected
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      LANGSMITH_API_KEY: ${LANGSMITH_API_KEY}
      PORT: ${PORT}
    volumes:
      - ./core:/app  # Mount the application code to detect live changes
    networks:
      - backend
    stop_signal: SIGINT
    ports:
      - "3000:3000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2048M # Memory limit for the compose

  # speech-to-text:
  #   build: ./speechToText
  #   restart: unless-stopped
  #   environment:
  #     FLASK_ENV: ${FLASK_ENV} # Autorestarts flask when code changes are detected
  #     OPENAI_API_KEY: ${OPENAI_API_KEY}
  #     PORT: ${PORT_STT}
  #   volumes:
  #     - ./core:/app  # Mount the application code to detect live changes
  #   networks:
  #     - backend
  #   stop_signal: SIGINT
  #   ports:
  #     - "3001:3001"

networks:
  backend:
    driver: bridge